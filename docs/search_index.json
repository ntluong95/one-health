[["basic-data-analysis.html", "Chapter 2 Basic Data analysis 2.1 Introduction about work flow 2.2 Software installation 2.3 Create working environment 2.4 Data Manipulation 2.5 Data visualization 2.6 Communication with Rmarkdown 2.7 ShinyApp", " Chapter 2 Basic Data analysis 2.1 Introduction about work flow The picture below described about a normal working process of data analysis. First you must import your data. This typically means that you take data stored in a file, database, or web application programming interface (API), and load it into the software. In this course, we will work with .xlsx and .csv file, which are the most common type of storaging data The next steps are Tidying and Transforming your data. Combining 2 steps, we have the so-called Data Wrangling. Tidying your data means storing it in a consistent form that matches the semantics of the dataset with the way it is stored. In brief, when your data is tidy, each column is a variable, and each row is an observation. Once you have tidy data, a common first step is to transform it. Transformation includes narrowing in on observations of interest, creating new variables that are functions of existing variables, and calculating a set of summary statistics (like counts or means). Visualization is a fundamentally human activity. A good visualization will show you things that you did not expect, or raise new questions about the data. A good visualization might also hint that youre asking the wrong question, or you need to collect different data. Visualizations can surprise you, but dont scale particularly well because they require a human to interpret them. Models are complementary tools to visualization. Once you have made your questions sufficiently precise, you can use a model to answer them. Models are a fundamentally mathematical or computational tool, so they generally scale well. But every model makes assumptions, and by its very nature a model cannot question its own assumptions. That means a model cannot fundamentally surprise you. The last step of data science is Communication, an absolutely critical part of any data analysis project. It doesnt matter how well your models and visualization have led you to understand the data unless you can also communicate your results to others. 2.2 Software installation In this course, I will introduce you about the three most powerful statistical softwares including R, Python and STATA, their usage and their advantages as well as disadvantages. While R and Python is more a programming language, which can be a hurdle for some people, STATA is more user-friendly and balance between using Graphical User Interface (GUI) and saving script (do file). In short, youll need to install the following programs in order: R: A statistical programming language used to wrangle, analyze, and visualize data (mac, windows) RStudio: An interface for writing and running R code, which is a primary language for the quarter (link). You can download a developing version here, which will provide most up-to-date new features Python: Another programming language, be preferred in machine learning, deep learning, AI. In this tutorial, we will install Python indirectly through package reticulate in R. More details will be presented later Git: (Optional) A set of command-line tools for tracking changes to a project. This is likely already installed on Macs. The Windows download will come with Git Bash, a simple interface for executing Git commands (link) STATA: This is paid software. You have to buy it before use or you can download a trial version here The following sections have additional information about the purpose of each component, how to install it, and alternative configurations. 2.2.1 R 2.2.2 Rstudio 2.2.3 Python 2.2.4 Setting environment for R and Python 2.2.5 STATA 2.3 Create working environment 2.4 Data Manipulation 2.5 Data visualization 2.6 Communication with Rmarkdown 2.7 ShinyApp "]]
