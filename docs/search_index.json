[["index.html", "Applied Epidemiology in One Health Research Chapter 1 Basic Epidemiology", " Applied Epidemiology in One Health Research Author: Nguyn Thanh Lng Date updated: 2021-01-30 Chapter 1 Basic Epidemiology OBJECTIVES After reading this chapter, reader should be able to: Select the appropriate sampling strategy for a particular situation, taking into account the requirements, advantages and disadvantages of each method. Identify the different types of selection bias and assess whether or not a particular study is likely to suffer from excess selection bias Explain the different ways of measuring disease frequency and differentiate among counts, proportions, odds and rates Calculate and interpret the following measures of association: risk ratio, odds ratio, incidence rate ratio, risk difference (attributable risk), attributable fraction (exposed), population attributable risk, attributable fraction (population) Understand the strength and weaknesses of various study designs for the identification and evaluation of causal factors. "],["about-the-book.html", "1.1 About the book", " 1.1 About the book Our rationale for doing research is to identify potentially causal associations between exposures and outcomes (the center of the diagram). In many cases, the exposures are risk factors and the outcome is a disease of interest. However, this is not the only scenario; for example, our outcome of interest might be a measure of productivity or food safety and the exposures might include certain diseases. Figure 1.1. Key components of epidemiologic research Ultimately, we aim to make causal inferences (bottom right of diagram) and Chapter 1 discusses some important concepts of causation as they relate to epidemiologic research. Any study starts with an overall study design and the main observational study types are discussed in Chapters 1.5. In any study, it is important to identify the target population and obtain a study group from it in a manner that does not lead to selection bias. Sampling and selection bias is discussed in Chapter 1.2. Once we have identified our study subjects, it is necessary to obtain data on exposure variables, extraneous variables and the outcome in a manner that does not lead to information bias (Chapter 1.6). Two important tools that are used in that process are questionnaires (Chapter 1.3) and diagnostic and screening tests (Chapter 1.3). In order to start the process of establishing an association between exposure and outcome, we need to settle on a measure of disease frequency (Chapter 1.3) and select a measure of association (Chapter 1.4) that fits the context. In many cases, the study design will determine the measures that are appropriate. Confounding bias is a major concern in observational studies, and the identification of factors that should be controlled as confounders is featured in Chapter 1.6. Basic data analysis will be presented in Chapter 2. You will learn essential skills to conduct data analysis with different programming languages such as R and Python or statistical software like STATA. Chapter 2.6 will provides you a road map for investigators starting into the analysis of an epidemiologic dataset. You will also introduced on how to communicate your works with other scientists and readers using Rmarkdown (Chapter 2.7) and ShinyApp (Chapter 2.8). With our data in hand, we are now able to begin to model relationships with the intent of estimating causal effects of exposure (Chapter 3). Individual chapters are dedicated to the analyses appropriate for outcomes that are continuous (Chapter 3.2), dichotomous (Chapter 3.3), nominal/ordinal (Chapter 3.4), count (Chapter 3.5) and time-to-event data (Chapter 3.6). Chapter 3.1 presents some general guide lines on model-building techniques that are applicable to all types of model. In one health epidemiologic research, we often encounter clustered or correlated data and these present major challenges in their analyses. Chapter 3.7.1 introduces these while Chapters 3.7.2 and Chapters 3.7.3 focus on mixed (random effects) models for continuous and discrete outcomes. Chapters 3.7.4 presents some alternative methods of analysis for dealing with clustered data. Other important tools in epidemiology, including Risk analysis (Chapter 4), Spatial epidemiology (Chapter 5), Estimating true prevalence of a diseases (Chapter 6) and Infections diseases modelling (Chapter 7) will also be discussed Other models and tools will be mentioned in Chapter 8. Structured reviews and assessments of the literature in the form of meta-analyses are becoming increasingly important and are introduced in Chapter 8.3. In Chapter 9, we will introduce about digital data collection tool (Chapter 9.1) and visualization tools (Chapter 9.2) "],["sampling.html", "1.2 Sampling", " 1.2 Sampling Chapter 2 v√† Chapter 12 "],["measures-of-diseases-frequency.html", "1.3 Measures of diseases frequency", " 1.3 Measures of diseases frequency Chapter 4 "],["measures-of-association.html", "1.4 Measures of association", " 1.4 Measures of association Chapter 6 "],["introduction-about-different-studies-design.html", "1.5 Introduction about different studies design", " 1.5 Introduction about different studies design 1.5.1 Introduction about observational studies Chapter 7 1.5.2 Cohort studies Chapter 8 1.5.3 Case-control studies Chapter 9 1.5.4 Hybrid study designs Chapter 10 1.5.5 Longitudinal study and time series data To be searched 1.5.6 Controlled trials Chapter 11 "],["confounder-bias.html", "1.6 Confounder bias", " 1.6 Confounder bias Chapter 13 "],["basic-data-analysis.html", "Chapter 2 Basic Data analysis ", " Chapter 2 Basic Data analysis "],["introduction-about-work-flow.html", "2.1 Introduction about work flow", " 2.1 Introduction about work flow The picture below described about a normal working process of data analysis. First you must import your data. This typically means that you take data stored in a file, database, or web application programming interface (API), and load it into the software. In this course, we will work with .xlsx and .csv file, which are the most common type of storaging data. Source: R for Data Science book The next steps are Tidying and Transforming your data. Combining 2 steps, we have the so-called Data Wrangling. Tidying your data means storing it in a consistent form that matches the semantics of the dataset with the way it is stored. In brief, when your data is tidy, each column is a variable, and each row is an observation. Once you have tidy data, a common first step is to transform it. Transformation includes narrowing in on observations of interest, creating new variables that are functions of existing variables, and calculating a set of summary statistics (like counts or means). Visualization is a fundamentally human activity. A good visualization will show you things that you did not expect, or raise new questions about the data. A good visualization might also hint that youre asking the wrong question, or you need to collect different data. Visualizations can surprise you, but dont scale particularly well because they require a human to interpret them. Models are complementary tools to visualization. Once you have made your questions sufficiently precise, you can use a model to answer them. Models are a fundamentally mathematical or computational tool, so they generally scale well. But every model makes assumptions, and by its very nature a model cannot question its own assumptions. That means a model cannot fundamentally surprise you. The last step of data science is Communication, an absolutely critical part of any data analysis project. It doesnt matter how well your models and visualization have led you to understand the data unless you can also communicate your results to others. "],["software-installation.html", "2.2 Software installation", " 2.2 Software installation In this course, I will introduce you about the three most powerful statistical softwares including R, Python and STATA, their usage and their advantages as well as disadvantages. While R and Python is more a programming language, which can be a hurdle for some people, STATA is more user-friendly and balance between using Graphical User Interface (GUI) and saving script (do file). In short, youll need to install the following programs in order: R: A statistical programming language used to wrangle, analyze, and visualize data (mac, windows) RStudio: An interface for writing and running R code, which is a primary language for the quarter (link). You can download a developing version here, which will provide most up-to-date new features Python: Another programming language, be preferred in machine learning, deep learning, AI. In this tutorial, we will install Python indirectly through package reticulate in R. More details will be presented later Git: (Optional) A set of command-line tools for tracking changes to a project. This is likely already installed on Macs. The Windows download will come with Git Bash, a simple interface for executing Git commands (link) STATA: This is paid software. You have to buy it before use or you can download a trial version here The following sections have additional information about the purpose of each component, how to install it, and alternative configurations. 2.2.1 R R is a popular data science language used to download, analyze, and visualize data. You can download it at the appropriate link for your operating system (mac, windows). At the link, click the appropriate download link and follow instructions: To install package in R, type the following code to the console. For instance, you want to install tidyverse package install.packages(&quot;tidyverse&quot;) To call tidyverse package library(tidyverse) 2.2.2 Rstudio The primary programming language we will use throughout the course is R. Its a very powerful statistical programming language that is built to work well with large and diverse datasets. While you are able to execute R scripts without an interface, the RStudio interface provides a wonderful way to engage with the R language. Importantly, you cannot use the RStudio interface until you have installed R. To download the RStudio program, select the installer for your operating system at this link. Make sure to scroll down to download a free version of RStudio: 2.2.3 Python Python is a very popular all-purpose programming language that is making a major impact in the data-science arena. Some data scientists, and even some organizations, believe they have to pick between R or Python. However, this turns out to be a false choice. In fact, results from a surveys showed that many data science teams today are bilingual, leveraging both R and Python in their work. And while both languages have unique strengths, these teams frequently struggle to use them together. Rstudio provides a prefect environment for data scientist through a package reticulate. Rstudio can be a potentially platform for data scientist who are using solely R or Python, or using both 2.2.4 Setting environment for R and Python Firstly, you have to install reticulate package: install.packages(&quot;reticulate&quot;) Secondly, install the miniconda environment. I suggest you should install miniconda in your local disk, not your OS disk (i.e Disk C) reticulate::install_miniconda(&quot;D:/Python&quot;) reticulate::use_condaenv(&quot;D:/Python/envs/r-reticulate&quot;) Thirdly, try to install Python package. There are two ways to do it, Reticulate style and Python style Reticulate style library(reticulate) py_install(&quot;pandas&quot;) py_install(&quot;matplotlib&quot;) Python style Set Python PATH through Terminal. You copy this code and paste into Terminal console in your Rstudio: setx PATH \"%PATH%;D:\\Python\\envs\\r-reticulate\\Scripts\" Then try to run this code to install pandas package: python -m pip install pandas 2.2.5 STATA This is paid software. You have to buy it before use or you can download a trial version here If you want to use STATA in Rstudio, you can do it through statamarkdown package. Detail will be dicussed further in this document. install.packages(&quot;Statamarkdown&quot;) library(Statamarkdown) stataexe &lt;- &quot;C:/Program Files/Stata16/StataSE-64.exe&quot; knitr::opts_chunk$set(engine.path=list(stata=stataexe)) "],["create-working-environment.html", "2.3 Create working environment", " 2.3 Create working environment Git is a version control system that provides a set of commands that allow you to manage changes to a project (much more on this in module-3). For now, youll need to download and install the software. Note, if you are using a Windows machine, this will install a program called Git Bash, which provides a text-based interface for executing commands on your computer. To setup Git in your Rstudio, you can visit this link. For alternative/additional Windows command-line tools, see below: Git Bash Because well primarily use the command line for implementing version control (i.e., keeping track of changes to our code), we can use a command-line tool that ships with the version control software, Git. When you download the Git software on Windows, the Git Bash user-interface will be installed. You can then navigate to Git Bash from your Desktop / Start Menu, and you will be able to use the appropriate syntax to keep track of code changes. Windows Bash With the release of Windows 10, Windows began providing command line (bash) support. If you already have Windows 10, here are a few instructions for installing bash capabilities. This requires that you switch to 64 bit windows, and follow the instructions above. While this will provide you with direct bash capabilities, you may run into challenges along the way (I have not tested these instructions). Note, you will still need to install Git in addition to Windows Bash. Powershell (Windows Management Framework) If you want to explore more robust command-line alternatives for Windows, the Windows Management Framework (including a program called Powershell) seems to be a preferred standard. Powershell will provide a simple text-based interface for inputing commands. Note, you will still need to install Git in addition to Powershell. "],["data-manipulation.html", "2.4 Data Manipulation", " 2.4 Data Manipulation "],["data-visualization.html", "2.5 Data visualization", " 2.5 Data visualization "],["communication-with-rmarkdown.html", "2.6 Communication with Rmarkdown", " 2.6 Communication with Rmarkdown "],["shinyapp.html", "2.7 ShinyApp", " 2.7 ShinyApp "],["a-structred-approach-to-data-analysis.html", "2.8 A structred approach to data analysis", " 2.8 A structred approach to data analysis "],["regression-models.html", "Chapter 3 Regression models ", " Chapter 3 Regression models "],["model-buidling-strategy.html", "3.1 Model buidling strategy", " 3.1 Model buidling strategy "],["linear-regression.html", "3.2 Linear regression", " 3.2 Linear regression "],["logistic-regression.html", "3.3 Logistic regression", " 3.3 Logistic regression "],["modelling-multinomial-data.html", "3.4 Modelling multinomial data", " 3.4 Modelling multinomial data "],["modelling-count-and-rate-data.html", "3.5 Modelling count and rate data", " 3.5 Modelling count and rate data "],["modelling-survival-data.html", "3.6 Modelling survival data", " 3.6 Modelling survival data "],["modelling-clustered-data.html", "3.7 Modelling clustered data", " 3.7 Modelling clustered data 3.7.1 Introduction to clustered data 3.7.2 Mixed model for continous data 3.7.3 Mixed model for discrete data 3.7.4 Alternative approach to dealing with clustered data "],["longitudinal-study-and-time-series-data-1.html", "3.8 Longitudinal study and time series data", " 3.8 Longitudinal study and time series data "],["controlled-trials-1.html", "3.9 Controlled trials", " 3.9 Controlled trials "],["risk-analysis.html", "Chapter 4 Risk analysis", " Chapter 4 Risk analysis "],["spatial-epidemiology.html", "Chapter 5 Spatial Epidemiology ", " Chapter 5 Spatial Epidemiology "],["introduction-about-qgis.html", "5.1 Introduction about QGIS", " 5.1 Introduction about QGIS "],["spatial-epidemiology-1.html", "5.2 Spatial Epidemiology", " 5.2 Spatial Epidemiology "],["estimating-true-prevalence-of-a-disease.html", "Chapter 6 Estimating true prevalence of a disease ", " Chapter 6 Estimating true prevalence of a disease "],["se-and-sp-estimations-using-logistic-regression.html", "6.1 Se and Sp estimations using logistic regression", " 6.1 Se and Sp estimations using logistic regression "],["estimate-true-prevalence-without-a-gold-standard.html", "6.2 Estimate true prevalence without a gold standard", " 6.2 Estimate true prevalence without a gold standard "],["infectious-diseases-modelling.html", "Chapter 7 Infectious Diseases Modelling ", " Chapter 7 Infectious Diseases Modelling "],["introduction-about-compartmental-model.html", "7.1 Introduction about compartmental model", " 7.1 Introduction about compartmental model "],["introduction-about-system-dynamic-modelling.html", "7.2 Introduction about system dynamic modelling", " 7.2 Introduction about system dynamic modelling "],["other-models.html", "Chapter 8 Other models ", " Chapter 8 Other models "],["structure-equation-modelling.html", "8.1 Structure Equation Modelling", " 8.1 Structure Equation Modelling "],["network-analysis.html", "8.2 Network analysis", " 8.2 Network analysis "],["meta-analysis.html", "8.3 Meta analysis", " 8.3 Meta analysis "],["other-tools.html", "Chapter 9 Other tools ", " Chapter 9 Other tools "],["digital-data-collection.html", "9.1 Digital data collection", " 9.1 Digital data collection "],["powerbi.html", "9.2 PowerBI", " 9.2 PowerBI "]]
